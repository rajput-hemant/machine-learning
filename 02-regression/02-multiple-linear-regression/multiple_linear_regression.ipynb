{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CazISR8X_HUG"},"source":["# Multiple Linear Regression"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Q. What is Multiple Linear Regression?**\n"," - Multiple Linear Regression is a statistical technique that uses several explanatory variables to predict the outcome of a response variable.\n","\n","**Q. What is the difference between Simple Linear Regression and Multiple Linear Regression?**\n","  - Simple Linear Regression uses only one explanatory variable to predict the outcome of a response variable, whereas Multiple Linear Regression uses several explanatory variables to predict the outcome of a response variable.\n","\n","**Q. What is the goal of Multiple Linear Regression?**\n","  - The goal of Multiple Linear Regression is to find the best fitting line that represents the relationship between the explanatory variables and the response variable.\n","\n","**Assumptions of Multiple Linear Regression**\n","  - The assumptions of Multiple Linear Regression are:\n","    - Linearity\n","    - Homoscedasticity\n","    - Multivariate normality\n","    - Independence of errors\n","    - Lack of multicollinearity\n","  \n","\n","**Methods of Building a Multiple Linear Regression Model**\n","  - There are two methods of building a Multiple Linear Regression model:\n","    - _All-in_\n","      - Throw in all the variables and let the model decide which variables are significant.\n","      - When you have Prior Knowledge about the data.\n","      - You are asked/have to build a model with all the variables.\n","      - Preparing for Backward Elimination.\n","      \n","    - _Backward Elimination_ \n","      - Select a significance level to stay in the model (e.g. SL = 0.05).\n","      - Fit the full model with all possible predictors.\n","      - Consider the predictor with the highest P-value. If P > SL, go to Step 4, otherwise go to FINISHED.\n","      - Remove the predictor.\n","      - Fit model without this variable.        \n","\n","    - _Forward Selection_\n","      - Select a significance level to enter the model (e.g. SL = 0.05).\n","      - Fit all simple regression models y ~ Xn. Select the one with the lowest P-value.\n","      - Keep this variable and fit all possible models with one extra predictor added to the one(s) you already have.\n","      - Consider the predictor with the lowest P-value. If P < SL, go to Step 3, otherwise go to FINISHED.\n","      \n","      **FIN:** Keep the previous model.\n","\n","    - _Bidirectional Elimination_\n","      - Select a significance level to enter and to stay in the model (e.g. SLENTER = 0.05, SLSTAY = 0.05).\n","      - Perform the next step of Forward Selection (new variables must have: P < SLENTER to enter).\n","      - Perform all steps of Backward Elimination (old variables must have: P < SLSTAY to stay).\n","      - No new variables can enter and no old variables can exit.\n","    \n","    - _Score Comparison_\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOyqYHTk_Q57"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"T_YHJjnD_Tja"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vgC61-ah_WIz"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"UrxyEKGn_ez7"},"outputs":[],"source":["dataset = pd.read_csv('50_Startups.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"colab_type":"code","executionInfo":{"elapsed":552,"status":"ok","timestamp":1586353652778,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"GOB3QhV9B5kD","outputId":"4a05377a-2db2-43fc-b824-a0710448baee"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VadrvE7s_lS9"},"source":["## Encoding categorical data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","id":"wV3fD1mbAvsh"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Encoding the Independent Variable (State)\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","\n","X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"colab_type":"code","executionInfo":{"elapsed":616,"status":"ok","timestamp":1586353657759,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"4ym3HdYeCGYG","outputId":"ce09e670-cf06-4a1c-f5b0-89422aae0496"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WemVnqgeA70k"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","id":"Kb_v_ae-A-20"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k-McZVsQBINc"},"source":["## Training the Multiple Linear Regression model on the Training set"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":757,"status":"ok","timestamp":1586353664008,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"ywPjx0L1BMiD","outputId":"099836bc-4d85-4b4f-a488-093faf02e8cb"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LinearRegression\n","\n","regressor = LinearRegression()\n","regressor.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xNkXL1YQBiBT"},"source":["## Predicting the Test set results"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"colab_type":"code","executionInfo":{"elapsed":951,"status":"ok","timestamp":1586353666678,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"TQKmwvtdBkyb","outputId":"493436bf-a4ae-4374-ca16-0b0c25d19457"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[103015.2  103282.38]\n"," [132582.28 144259.4 ]\n"," [132447.74 146121.95]\n"," [ 71976.1   77798.83]\n"," [178537.48 191050.39]\n"," [116161.24 105008.31]\n"," [ 67851.69  81229.06]\n"," [ 98791.73  97483.56]\n"," [113969.44 110352.25]\n"," [167921.07 166187.94]]\n"]}],"source":["y_pred = regressor.predict(X_test)\n","np.set_printoptions(precision=2) # 2 decimal places\n","print(np.concatenate(\n","    (\n","    y_pred.reshape(len(y_pred), 1), # reshape vector from horizontal to vertical\n","    y_test.reshape(len(y_test), 1)\n","    ), 1 # concatenate horizontally, 0 for vertically\n","))\n","\n","# [[predicted, actual], ...]"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7","name":"Multiple Linear Regression","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
